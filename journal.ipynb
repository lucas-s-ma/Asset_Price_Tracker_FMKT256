{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Automatic Asset Price Collector</b><br>\n",
    "<b>Author: Lucas Ma - Duke 27'</b>\n",
    "\n",
    "This program dynamically collects security prices as traced by FMKT256 automatically. Ensure you have installed \"requests\" and \"bs4\" packages in your python environment. The output has been arranged by the order as appeared in the excel spreadsheet, so feel free to directly copy and paste.\n",
    "\n",
    "If you do not have these packages, open your terminal and type \"pip install requests\" and \"pip install bs4\" sequentially.\n",
    "\n",
    "Enjoy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0970\t1.3086\t148.3290\t39,242.51\t19,066.47\t8,190.61\t42,080.37\t5,751.13\t0.926%\t2.242%\t4.200%\t4.011%\t2,636.60\t77.55\t62,356.10\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Function to scrape webpage based on a CSS selector\n",
    "def scrape_website_by_css(url, css_selector):\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36',\n",
    "            'Referer': 'https://www.google.com/'\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  \n",
    "\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        elements = soup.select(css_selector)\n",
    "\n",
    "        extracted_text = [element.get_text(strip=True) for element in elements]\n",
    "        return \" \".join(extracted_text)  \n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to scrape multiple websites based on corresponding CSS selectors\n",
    "def scrape_websites_by_css_labels(urls, css_selectors):\n",
    "    all_results = []\n",
    "    \n",
    "    for url, css_selector in zip(urls, css_selectors):\n",
    "        # print(f\"Scraping {url} with selector {css_selector}...\")\n",
    "        match = scrape_website_by_css(url, css_selector)\n",
    "        \n",
    "        if match:\n",
    "            all_results.append(match)\n",
    "        else:\n",
    "            all_results.append(\"No matches or error occurred.\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    websites = [\n",
    "        \"https://finance.yahoo.com/quote/EURUSD%3DX/\", # Euro/USD\n",
    "        \"https://finance.yahoo.com/quote/GBPUSD%3DX/\", # STG/USD\n",
    "        \"https://finance.yahoo.com/quote/JPY%3DX/\", # USD/JPY\n",
    "        \"https://finance.yahoo.com/quote/%5EN225/\", # NIKKEI\n",
    "        \"https://finance.yahoo.com/quote/%5EGDAXI/\", # DAX\n",
    "        \"https://finance.yahoo.com/quote/%5EFTSE/\", # FTSE\n",
    "        \"https://finance.yahoo.com/quote/%5EDJI/\", # DOW\n",
    "        \"https://finance.yahoo.com/quote/%5EGSPC/\", # S&P\n",
    "        \"https://www.worldgovernmentbonds.com/\", # Japan, German, UK, and US 10Y\n",
    "        \"https://www.worldgovernmentbonds.com/\",\n",
    "        \"https://www.worldgovernmentbonds.com/\",\n",
    "        \"https://www.worldgovernmentbonds.com/\",\n",
    "        \"https://finance.yahoo.com/quote/GC%3DF/\", # Gold\n",
    "        \"https://finance.yahoo.com/quote/BZ=F/\", # Oil\n",
    "        \"https://finance.yahoo.com/quote/BTC-USD/\" # BTC\n",
    "    ]\n",
    "\n",
    "    css_selectors = [\n",
    "        \".livePrice span\",\n",
    "        \".livePrice span\",\n",
    "        \".livePrice span\",\n",
    "        \".livePrice span\",\n",
    "        \".livePrice span\",\n",
    "        \".livePrice span\",\n",
    "        \".livePrice span\",\n",
    "        \".livePrice span\",\n",
    "        \"tr:nth-child(2) .linkT10Y\",\n",
    "        \"tr:nth-child(7) .linkT10Y\",\n",
    "        \"tr:nth-child(37) .linkT10Y\",\n",
    "        \"tr:nth-child(35) .linkT10Y\",\n",
    "        \".livePrice span\",\n",
    "        \".livePrice span\",\n",
    "        \".livePrice span\"\n",
    "    ]\n",
    "    \n",
    "    results = scrape_websites_by_css_labels(websites, css_selectors)\n",
    "    excel_ready_output = \"\\t\".join(results)\n",
    "\n",
    "    # print(\"\\nCopy and paste this into Excel:\")\n",
    "    print(excel_ready_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
